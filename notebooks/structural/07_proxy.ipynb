{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Patterns\n",
    "\n",
    "The creational patterns are guidelines suggested to compose objects in a way that allows to perform new functionalities. Those new functionalities would be harder to do without the new class/function created.\n",
    "\n",
    "The structural patterns at the same time allows dealing with across entities relationships in an easier and managable way.\n",
    "\n",
    "In simple words: **How to compose complex objects**\n",
    "\n",
    "The seven structural patterns available are:\n",
    "1. Adapter\n",
    "2. Bridge\n",
    "3. Composite\n",
    "4. Decorator\n",
    "5. Facade\n",
    "6. Flyweight\n",
    "7. Proxy\n",
    "\n",
    "Each of those previous patterns are unique, and can be used in different situations and conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the proxy?**\n",
    "\n",
    "It is a class that acts like a bodyguard. It acts similarly as the instance declared inside the proxy, but it has many safe-checks to verify before executing the instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When should we use it?**\n",
    "\n",
    "This is suitable when the execution of an specific model (in the Context of MLE) might be problematic. Why? we can get different results if provide data in a different way, if we provide too much information, or also when given wrong information.\n",
    "\n",
    "This also can be used for lazy execution of the models. However, this might introduce an additional overhead if you're application is not ready for lazy components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario**\n",
    "\n",
    "You need to create embeddings for a RAG application. You'll receive different chuncks of text and produce the embedding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antipattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is most easiest and repeated antipattern, I've seen in the GenAI applications. Typically, just people creates a simple class that executes the transformer based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self):\n",
    "        # this model only supports up to 512 tokens of max lenght\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-small-v2\")\n",
    "        self.model = AutoModel.from_pretrained(\"intfloat/e5-small-v2\")\n",
    "\n",
    "    def predict(self, texts):\n",
    "        inputs = self.tokenizer(\n",
    "            texts, padding=False, truncation=True, return_tensors=\"pt\", max_length=512\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            return self.model(**inputs).last_hidden_state.sum(dim=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a bigger text with 1000 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For sake of simplicify, let's considerate each word a token.** \n",
    "\n",
    "Why to consider this: I don't know in deep how the previous model considerates a token, but as a rule of thumb, a token can be considered as a word. Considering that there is a high risk that the model uses tokens just syllables of the words, let's consider that each word have at least 2 syllables. Thus, the maximum quantity of words to process is around 500 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're going to calculate the embedding of the next text, let's see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_text = \"\"\" \n",
    "The Natural Wonders of Ecuador\n",
    "\n",
    "Ecuador is one of the smallest countries in South America, yet it is also one of the most biologically and geographically diverse places on Earth. Nestled between Colombia and Peru, and crossed by the equator from which it takes its name, Ecuador is a land where volcanoes rise majestically above the clouds, lush rainforests thrive with vibrant life, and pristine coastlines meet the vast Pacific Ocean. Despite its modest size, the country contains nearly every ecosystem imaginable, making it a natural paradise and a true wonder of our planet. From the Galápagos Islands to the Amazon Basin, Ecuador offers countless breathtaking landscapes and ecosystems that amaze scientists, travelers, and locals alike.\n",
    "\n",
    "The Galápagos Islands: A Living Laboratory\n",
    "\n",
    "Perhaps the most famous natural wonder of Ecuador is the Galápagos Islands, an archipelago located about 1,000 kilometers off the country’s coast. These volcanic islands became legendary after Charles Darwin visited them in 1835, inspiring his groundbreaking theory of evolution by natural selection. What makes the Galápagos truly remarkable is the high level of endemism: many species, such as the giant tortoise, marine iguana, and blue-footed booby, exist nowhere else on Earth.\n",
    "\n",
    "The islands are also unique for their relatively fearless wildlife. Visitors can snorkel alongside playful sea lions, observe penguins swimming near the equator, and watch frigate birds inflate their bright red throats to attract mates. The Galápagos Marine Reserve, one of the largest in the world, protects a stunning diversity of underwater life, including hammerhead sharks, manta rays, and sea turtles. This extraordinary ecosystem makes the Galápagos one of the greatest natural wonders not only of Ecuador but of the entire world.\n",
    "\n",
    "The Amazon Rainforest: The Green Heart of Ecuador\n",
    "\n",
    "In the eastern part of Ecuador lies another natural wonder: the Amazon rainforest, known locally as “El Oriente.” This vast and humid region is part of the Amazon Basin, which is often called the “lungs of the planet” for its critical role in producing oxygen and regulating global climate. Ecuador’s portion of the Amazon may be relatively small compared to that of Brazil or Peru, but it is no less impressive.\n",
    "\n",
    "The Ecuadorian Amazon is a treasure trove of biodiversity. It is home to jaguars, tapirs, pink river dolphins, anacondas, and thousands of bird species. The rainforest also harbors an incredible variety of plants, many of which are used for medicinal purposes by Indigenous communities. National parks such as Yasuní and Cuyabeno offer protected spaces where visitors can explore the dense jungle, paddle through blackwater lagoons, and learn about traditional knowledge from Indigenous groups like the Kichwa, Shuar, and Huaorani.\n",
    "\n",
    "What makes the Amazon a true wonder is not just its beauty and biodiversity but also its cultural richness. The people who live in the forest have developed deep spiritual and practical connections with the land, reminding the world of the importance of living in harmony with nature.\n",
    "\n",
    "The Andean Highlands: Volcanoes and Sacred Mountains\n",
    "\n",
    "Stretching across the center of the country, the Andes Mountains create a dramatic backbone for Ecuador. This highland region, known as the Sierra, is dotted with snowcapped peaks, fertile valleys, and crystal-clear lakes. The Avenue of the Volcanoes, a term coined by the German explorer Alexander von Humboldt, refers to the string of volcanoes that line this part of the Andes. Among them is Cotopaxi, one of the highest active volcanoes in the world, whose perfectly symmetrical cone is an icon of Ecuador’s landscape.\n",
    "\n",
    "Another marvel is Chimborazo, the highest mountain in Ecuador. Due to the bulge of the Earth at the equator, Chimborazo’s summit is the farthest point from the center of the planet, even farther than Mount Everest. Climbing this sacred mountain is a dream for mountaineers, but even those who admire it from afar are struck by its grandeur.\n",
    "\n",
    "The highlands are also filled with enchanting lakes formed by volcanic activity. One of the most spectacular is Quilotoa, a crater lake with striking turquoise waters. Hiking around Quilotoa offers not only breathtaking views but also the chance to encounter Indigenous villages and markets, where traditional weaving and crafts reflect the cultural richness of the Sierra.\n",
    "\n",
    "The Cloud Forests: Where Mist Meets Life\n",
    "\n",
    "On the western slopes of the Andes lies another natural wonder that surprises many visitors: the cloud forests. These lush, green forests thrive in areas of constant mist and rainfall, creating a magical environment where moss, orchids, and bromeliads grow abundantly.\n",
    "\n",
    "The Mindo region is perhaps the most famous cloud forest destination in Ecuador. It is known as a paradise for birdwatchers, with over 500 species recorded, including the dazzling Andean cock-of-the-rock and dozens of species of hummingbirds. Waterfalls, butterfly farms, and canopy ziplines make the cloud forests a haven for both adventure and relaxation.\n",
    "\n",
    "What makes these forests especially important is their role as a transition zone between the Andes and the coastal lowlands, creating a unique mix of species. Sadly, cloud forests are among the most threatened ecosystems due to deforestation, but conservation efforts in Ecuador are helping to protect their extraordinary beauty.\n",
    "\n",
    "The Pacific Coast: Sun, Sand, and Marine Life\n",
    "\n",
    "Ecuador’s Pacific coast is another natural treasure that often surprises travelers. With more than 2,200 kilometers of shoreline, the coast offers sandy beaches, rocky cliffs, and rich marine ecosystems. The coastal region is also home to Machalilla National Park, which includes the famous Isla de la Plata, sometimes called the “Poor Man’s Galápagos” for its similar wildlife, including blue-footed boobies and sea turtles.\n",
    "\n",
    "Between June and September, humpback whales migrate to Ecuador’s warm coastal waters to breed and give birth. Whale watching in places like Puerto López is an unforgettable experience, as these gentle giants leap and splash near the boats. Coastal mangroves also serve as crucial ecosystems, providing habitats for crabs, birds, and fish while protecting the shoreline from erosion.\n",
    "\n",
    "The Cultural Connection to Nature\n",
    "\n",
    "What makes Ecuador’s natural wonders even more special is their deep connection to culture. For Indigenous peoples, mountains like Cotopaxi and Chimborazo are sacred, representing powerful spirits. The Amazon is not just a forest but a living home filled with ancestral knowledge. The coast has been a source of livelihood and spiritual meaning for centuries. Even in the Galápagos, local communities work to balance conservation with sustainable living.\n",
    "\n",
    "This strong bond between people and nature reinforces the idea that Ecuador’s wonders are not only landscapes but also integral parts of identity and heritage.\n",
    "\n",
    "Conclusion: A Small Country with Infinite Wonders\n",
    "\n",
    "Ecuador may be one of the smallest countries in South America, but it is an immense treasure in terms of natural beauty and diversity. From the remote Galápagos Islands to the dense Amazon rainforest, from the towering volcanoes of the Andes to the misty cloud forests and golden beaches of the Pacific coast, Ecuador is a land of contrasts and marvels.\n",
    "\n",
    "Its ecosystems provide sanctuary to countless species, inspire scientific discovery, and offer breathtaking experiences to all who visit. At the same time, they remind humanity of the urgent need to protect and cherish the natural world. In a single country, Ecuador condenses the richness of the planet, making it a true jewel of nature and a place where the wonders of Earth come to life.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = embedding_model.predict([random_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review what is the result if we just provide that first 500 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = embedding_model.predict([random_text[:500]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the sentence similarity between just 500 words and all the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93753016]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(result, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why using all the text and just the 500 words produces similar results? Where are feeding into the embedding model too much text, when it surpasses the model context, it truncates. \n",
    "\n",
    "It is an antipattern because it violates the model conditions for a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to solve the antipattern?**\n",
    "\n",
    "We need some sanity checks before the model execution otherwise, this will not be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewEmbedding:\n",
    "    def __init__(self):\n",
    "        # this model only supports up to 512 tokens of max lenght\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-small-v2\")\n",
    "        self.model = AutoModel.from_pretrained(\"intfloat/e5-small-v2\")\n",
    "\n",
    "    def sentence_length_review(self, text):\n",
    "        words = text.split(\" \")\n",
    "        if len(words) > 512:\n",
    "            raise ValueError(\"Text exceeds the maximum length of 512 tokens.\")\n",
    "\n",
    "    def predict(self, texts):\n",
    "        for text in texts:\n",
    "            self.sentence_length_review(text)\n",
    "        inputs = self.tokenizer(\n",
    "            texts, padding=False, truncation=True, return_tensors=\"pt\", max_length=512\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            return self.model(**inputs).last_hidden_state.sum(dim=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, it becomes right now into a Proxy class which validates the input before calling the main class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding_model = NewEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Text exceeds the maximum length of 512 tokens.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result3 = \u001b[43mnew_embedding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrandom_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mNewEmbedding.predict\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts):\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msentence_length_review\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m.tokenizer(texts, padding=\u001b[38;5;28;01mFalse\u001b[39;00m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, max_length=\u001b[32m512\u001b[39m)\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mNewEmbedding.sentence_length_review\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m      8\u001b[39m words = text.split(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(words) > \u001b[32m512\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mText exceeds the maximum length of 512 tokens.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Text exceeds the maximum length of 512 tokens."
     ]
    }
   ],
   "source": [
    "result3 = new_embedding_model.predict([random_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw before, it breakes the execution avoiding that the model is executed. This allows to have a gatekeeper who selects when and when not running the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:**\n",
    "\n",
    "The main difference between the decorator and the proxy is that Proxy defines the instances to run inside the class. The Proxy does not extend any class functionalities; while, the decorator can accept as input any class wanted to be decorated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
